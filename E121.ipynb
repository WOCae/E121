{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力: ['み', 'か'] -> 次の文字の予測: た\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# データの準備\n",
    "# ひらがな「み」「か」「た」の対応表\n",
    "char_to_idx = {'み': 0, 'か': 1, 'た': 2}\n",
    "idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "\n",
    "# シーケンスデータの作成\n",
    "sequences = [\n",
    "    ['み', 'か', 'た'],\n",
    "    ['か', 'た', 'み'],\n",
    "    ['た', 'み', 'か']\n",
    "]\n",
    "\n",
    "# 入力とラベルを数値に変換\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq in sequences:\n",
    "    X.append([char_to_idx[char] for char in seq[:-1]])  # 最後の文字を除く\n",
    "    y.append(char_to_idx[seq[-1]])  # 最後の文字\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hotエンコーディング\n",
    "X = to_categorical(X, num_classes=len(char_to_idx))\n",
    "y = to_categorical(y, num_classes=len(char_to_idx))\n",
    "\n",
    "# モデルの構築\n",
    "model = Sequential([\n",
    "    SimpleRNN(10, input_shape=(X.shape[1], X.shape[2]), activation='tanh'),\n",
    "    Dense(len(char_to_idx), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "\n",
    "# 予測\n",
    "def predict_next_char(input_seq):\n",
    "    input_encoded = [char_to_idx[char] for char in input_seq]\n",
    "    input_encoded = to_categorical(input_encoded, num_classes=len(char_to_idx))\n",
    "    input_encoded = input_encoded[np.newaxis, ...]  # バッチ次元を追加\n",
    "    prediction = model.predict(input_encoded, verbose=0)\n",
    "    predicted_idx = np.argmax(prediction)\n",
    "    return idx_to_char[predicted_idx]\n",
    "\n",
    "# テスト\n",
    "test_input = ['み', 'か']  # 例えば「み」「か」と入力\n",
    "predicted_char = predict_next_char(test_input)\n",
    "print(f\"入力: {test_input} -> 次の文字の予測: {predicted_char}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tkinter as tk\n",
    "\n",
    "# データの準備\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sequences = [line.strip() for line in f if line.strip()]\n",
    "    return sequences\n",
    "\n",
    "# 学習データの読み込み\n",
    "file_path = 'data.txt'\n",
    "sequences = load_data(file_path)\n",
    "\n",
    "# ユニークな文字を取得\n",
    "unique_chars = sorted(set(''.join(sequences)))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "# シーケンスデータの作成\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(len(seq) - 1):\n",
    "        X.append([char_to_idx[char] for char in seq[i:i+2]])  # 2文字ずつ\n",
    "        y.append(char_to_idx[seq[i+2]] if i + 2 < len(seq) else char_to_idx[seq[0]])  # 次の文字 or 循環\n",
    "\n",
    "    # 1文字で次を予測するケース\n",
    "    for i in range(len(seq)):\n",
    "        X.append([char_to_idx[seq[i]], char_to_idx[seq[i]]])  # 同じ文字を2回\n",
    "        y.append(char_to_idx[seq[(i + 1) % len(seq)]])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hotエンコーディング\n",
    "X = to_categorical(X, num_classes=len(char_to_idx))\n",
    "y = to_categorical(y, num_classes=len(char_to_idx))\n",
    "\n",
    "# モデルの構築\n",
    "model = Sequential([\n",
    "    SimpleRNN(10, input_shape=(X.shape[1], X.shape[2]), activation='tanh'),\n",
    "    Dense(len(char_to_idx), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "\n",
    "# 予測関数\n",
    "def predict_next_char(input_seq):\n",
    "    # 学習データにない文字が入力されている場合\n",
    "    if any(char not in char_to_idx for char in input_seq):\n",
    "        return \"未対応の文字が含まれています\"\n",
    "    \n",
    "    # 入力が2文字未満の場合、補完\n",
    "    if len(input_seq) < 2:\n",
    "        input_seq = input_seq * 2\n",
    "    \n",
    "    # 最後の2文字を使用して予測\n",
    "    input_encoded = [char_to_idx[char] for char in input_seq[-2:]]\n",
    "    input_encoded = to_categorical(input_encoded, num_classes=len(char_to_idx))\n",
    "    input_encoded = input_encoded[np.newaxis, ...]\n",
    "    prediction = model.predict(input_encoded, verbose=0)\n",
    "    predicted_idx = np.argmax(prediction)\n",
    "    return idx_to_char[predicted_idx]\n",
    "\n",
    "# TkinterによるGUI\n",
    "def on_input_change(event):\n",
    "    input_text = input_field.get()\n",
    "    if len(input_text) == 0:\n",
    "        result_label.config(text=\"文字を入力してください\")\n",
    "        return\n",
    "\n",
    "    predicted_char = predict_next_char(input_text)\n",
    "    result_label.config(text=f\"次の文字の予測: {predicted_char}\")\n",
    "\n",
    "# ウィンドウの作成\n",
    "window = tk.Tk()\n",
    "window.title(\"文字予測アプリ\")\n",
    "\n",
    "# ラベル\n",
    "instruction_label = tk.Label(window, text=\"任意の長さの文字を入力してください\")\n",
    "instruction_label.pack()\n",
    "\n",
    "# 入力フィールド\n",
    "input_field = tk.Entry(window)\n",
    "input_field.pack()\n",
    "\n",
    "# 入力フィールドの変更時に予測を実行\n",
    "input_field.bind(\"<KeyRelease>\", on_input_change)\n",
    "\n",
    "# 結果表示ラベル\n",
    "result_label = tk.Label(window, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "# アプリ実行\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. モデル学習・保存部分 (train_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9540 - accuracy: 0.0976\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9443 - accuracy: 0.0976\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9367 - accuracy: 0.0976\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9285 - accuracy: 0.0976\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.9206 - accuracy: 0.0976\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9130 - accuracy: 0.1220\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.9053 - accuracy: 0.1220\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8979 - accuracy: 0.1220\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8903 - accuracy: 0.1220\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8828 - accuracy: 0.1220\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8753 - accuracy: 0.1220\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8682 - accuracy: 0.1220\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8608 - accuracy: 0.1463\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8536 - accuracy: 0.1463\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.8462 - accuracy: 0.1707\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8397 - accuracy: 0.1707\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.8324 - accuracy: 0.1707\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8251 - accuracy: 0.1707\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8186 - accuracy: 0.1707\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8113 - accuracy: 0.1707\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.8048 - accuracy: 0.1707\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7977 - accuracy: 0.1707\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7906 - accuracy: 0.1951\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7841 - accuracy: 0.1951\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7771 - accuracy: 0.1951\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7704 - accuracy: 0.2195\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7639 - accuracy: 0.2195\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7570 - accuracy: 0.2195\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 2.7504 - accuracy: 0.2439\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7436 - accuracy: 0.2439\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7371 - accuracy: 0.2439\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7306 - accuracy: 0.2439\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7235 - accuracy: 0.2439\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.7170 - accuracy: 0.2683\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7103 - accuracy: 0.2683\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.7038 - accuracy: 0.2683\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6970 - accuracy: 0.2683\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6905 - accuracy: 0.2683\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6837 - accuracy: 0.2683\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6772 - accuracy: 0.2683\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6705 - accuracy: 0.2683\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6638 - accuracy: 0.2683\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6571 - accuracy: 0.2683\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6507 - accuracy: 0.2683\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6438 - accuracy: 0.2683\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6374 - accuracy: 0.2683\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.6302 - accuracy: 0.2683\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.6237 - accuracy: 0.2683\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6169 - accuracy: 0.2683\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6102 - accuracy: 0.2683\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.6030 - accuracy: 0.2683\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5965 - accuracy: 0.2683\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5898 - accuracy: 0.2683\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5827 - accuracy: 0.2683\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5761 - accuracy: 0.2683\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5695 - accuracy: 0.2683\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5631 - accuracy: 0.2683\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5559 - accuracy: 0.2683\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5496 - accuracy: 0.2683\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5428 - accuracy: 0.2683\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5361 - accuracy: 0.2683\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5292 - accuracy: 0.2683\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5229 - accuracy: 0.2439\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5163 - accuracy: 0.2439\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.5100 - accuracy: 0.2683\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.5032 - accuracy: 0.2683\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4966 - accuracy: 0.2683\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4902 - accuracy: 0.2683\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.4838 - accuracy: 0.2683\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4778 - accuracy: 0.2683\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4712 - accuracy: 0.2927\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4649 - accuracy: 0.2927\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4584 - accuracy: 0.3171\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4524 - accuracy: 0.3171\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.4461 - accuracy: 0.3171\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4400 - accuracy: 0.3171\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4337 - accuracy: 0.3171\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4279 - accuracy: 0.3171\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4216 - accuracy: 0.3171\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.4157 - accuracy: 0.3171\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.4096 - accuracy: 0.3171\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.4039 - accuracy: 0.3171\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3980 - accuracy: 0.3171\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3923 - accuracy: 0.3171\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3864 - accuracy: 0.3171\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3807 - accuracy: 0.3171\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3748 - accuracy: 0.3171\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 2.3693 - accuracy: 0.3171\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3635 - accuracy: 0.3171\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 2.3579 - accuracy: 0.3171\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.3522 - accuracy: 0.3171\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3466 - accuracy: 0.3171\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3409 - accuracy: 0.3171\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3353 - accuracy: 0.3415\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3294 - accuracy: 0.3415\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3236 - accuracy: 0.3415\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3181 - accuracy: 0.3415\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3122 - accuracy: 0.3415\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.3065 - accuracy: 0.3659\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.3006 - accuracy: 0.3659\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2948 - accuracy: 0.3659\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2892 - accuracy: 0.3659\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2833 - accuracy: 0.4146\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2777 - accuracy: 0.4390\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2717 - accuracy: 0.4390\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2663 - accuracy: 0.4390\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2605 - accuracy: 0.4390\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2548 - accuracy: 0.4390\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2489 - accuracy: 0.4390\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2434 - accuracy: 0.4390\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2376 - accuracy: 0.4390\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2321 - accuracy: 0.4390\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2262 - accuracy: 0.4634\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2206 - accuracy: 0.4634\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.2148 - accuracy: 0.4634\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.2092 - accuracy: 0.4634\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2035 - accuracy: 0.4634\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1980 - accuracy: 0.4634\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1924 - accuracy: 0.4634\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1868 - accuracy: 0.4634\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1815 - accuracy: 0.4634\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1758 - accuracy: 0.4634\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1702 - accuracy: 0.4634\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1650 - accuracy: 0.4634\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1594 - accuracy: 0.4634\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1539 - accuracy: 0.4634\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1485 - accuracy: 0.4878\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1428 - accuracy: 0.4878\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1376 - accuracy: 0.4878\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1321 - accuracy: 0.4878\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1265 - accuracy: 0.4878\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1212 - accuracy: 0.4878\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.1158 - accuracy: 0.4878\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.1103 - accuracy: 0.4878\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.1050 - accuracy: 0.5122\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0990 - accuracy: 0.5122\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0938 - accuracy: 0.5122\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0884 - accuracy: 0.5122\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0826 - accuracy: 0.5122\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0774 - accuracy: 0.5122\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0719 - accuracy: 0.5122\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0664 - accuracy: 0.5122\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0612 - accuracy: 0.5122\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0559 - accuracy: 0.5122\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0507 - accuracy: 0.5122\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0456 - accuracy: 0.5122\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0400 - accuracy: 0.5122\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0347 - accuracy: 0.5122\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0297 - accuracy: 0.5122\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0241 - accuracy: 0.5122\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0190 - accuracy: 0.5122\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 2.0141 - accuracy: 0.5122\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0089 - accuracy: 0.5122\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 2.0038 - accuracy: 0.5366\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9987 - accuracy: 0.5366\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9938 - accuracy: 0.5366\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9886 - accuracy: 0.5366\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9837 - accuracy: 0.5366\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9785 - accuracy: 0.5366\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9736 - accuracy: 0.5366\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9686 - accuracy: 0.5366\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9636 - accuracy: 0.5366\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9586 - accuracy: 0.5610\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9536 - accuracy: 0.5610\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9486 - accuracy: 0.5610\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9436 - accuracy: 0.5854\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9387 - accuracy: 0.5854\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9337 - accuracy: 0.5854\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9288 - accuracy: 0.5854\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.9237 - accuracy: 0.5854\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9186 - accuracy: 0.5854\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9136 - accuracy: 0.5854\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9086 - accuracy: 0.5854\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.9036 - accuracy: 0.5854\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8988 - accuracy: 0.6098\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8937 - accuracy: 0.6098\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8890 - accuracy: 0.6098\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8840 - accuracy: 0.6098\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8793 - accuracy: 0.6098\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8744 - accuracy: 0.6098\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8696 - accuracy: 0.6098\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8651 - accuracy: 0.6098\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8602 - accuracy: 0.6098\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8553 - accuracy: 0.6098\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8506 - accuracy: 0.6098\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8458 - accuracy: 0.6098\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8410 - accuracy: 0.6098\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8361 - accuracy: 0.6098\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8314 - accuracy: 0.6098\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8267 - accuracy: 0.6098\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8220 - accuracy: 0.6098\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8171 - accuracy: 0.6098\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.8125 - accuracy: 0.6098\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.8081 - accuracy: 0.6098\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.8035 - accuracy: 0.6098\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7989 - accuracy: 0.6098\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 1.7945 - accuracy: 0.6098\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7899 - accuracy: 0.6098\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7855 - accuracy: 0.6098\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7812 - accuracy: 0.6098\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7768 - accuracy: 0.6098\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7721 - accuracy: 0.6098\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7677 - accuracy: 0.6098\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7635 - accuracy: 0.6098\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 505us/step - loss: 1.7590 - accuracy: 0.6098\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7548 - accuracy: 0.6098\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7506 - accuracy: 0.6098\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7462 - accuracy: 0.6098\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7419 - accuracy: 0.6098\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7376 - accuracy: 0.6098\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7333 - accuracy: 0.6098\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7290 - accuracy: 0.6098\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.7249 - accuracy: 0.6098\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7203 - accuracy: 0.6098\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7161 - accuracy: 0.6098\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.7116 - accuracy: 0.6098\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7072 - accuracy: 0.6098\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.7031 - accuracy: 0.6098\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6988 - accuracy: 0.6098\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6942 - accuracy: 0.6098\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6903 - accuracy: 0.6098\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6859 - accuracy: 0.6098\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6816 - accuracy: 0.6098\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6774 - accuracy: 0.6098\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6731 - accuracy: 0.6341\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6693 - accuracy: 0.6341\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6647 - accuracy: 0.6341\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6609 - accuracy: 0.6341\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6566 - accuracy: 0.6341\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6523 - accuracy: 0.6341\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6487 - accuracy: 0.6341\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6444 - accuracy: 0.6341\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6404 - accuracy: 0.6341\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6363 - accuracy: 0.6341\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6321 - accuracy: 0.6341\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6283 - accuracy: 0.6341\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 505us/step - loss: 1.6242 - accuracy: 0.6341\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6203 - accuracy: 0.6341\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6162 - accuracy: 0.6341\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6121 - accuracy: 0.6341\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.6084 - accuracy: 0.6341\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6044 - accuracy: 0.6341\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.6004 - accuracy: 0.6341\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5964 - accuracy: 0.6341\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5928 - accuracy: 0.6341\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5890 - accuracy: 0.6341\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5850 - accuracy: 0.6341\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5813 - accuracy: 0.6341\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5774 - accuracy: 0.6341\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5734 - accuracy: 0.6341\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5697 - accuracy: 0.6341\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5657 - accuracy: 0.6341\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.5621 - accuracy: 0.6341\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5583 - accuracy: 0.6341\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5545 - accuracy: 0.6341\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5508 - accuracy: 0.6341\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 505us/step - loss: 1.5470 - accuracy: 0.6341\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5433 - accuracy: 0.6341\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5397 - accuracy: 0.6341\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5359 - accuracy: 0.6341\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5321 - accuracy: 0.6341\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5286 - accuracy: 0.6341\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5250 - accuracy: 0.6341\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.5209 - accuracy: 0.6341\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5174 - accuracy: 0.6341\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5136 - accuracy: 0.6341\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5097 - accuracy: 0.6341\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5060 - accuracy: 0.6341\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.5024 - accuracy: 0.6341\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4987 - accuracy: 0.6341\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4949 - accuracy: 0.6341\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4910 - accuracy: 0.6341\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4874 - accuracy: 0.6341\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4836 - accuracy: 0.6341\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.4801 - accuracy: 0.6341\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4764 - accuracy: 0.6341\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4727 - accuracy: 0.6341\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4691 - accuracy: 0.6341\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.4654 - accuracy: 0.6341\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4623 - accuracy: 0.6341\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4582 - accuracy: 0.6341\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 1.4548 - accuracy: 0.6341\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4511 - accuracy: 0.6341\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4476 - accuracy: 0.6341\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4439 - accuracy: 0.6341\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4401 - accuracy: 0.6341\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4365 - accuracy: 0.6341\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4327 - accuracy: 0.6341\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.4291 - accuracy: 0.6341\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4256 - accuracy: 0.6341\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4218 - accuracy: 0.6341\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4181 - accuracy: 0.6341\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.4146 - accuracy: 0.6341\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4109 - accuracy: 0.6341\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4074 - accuracy: 0.6341\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.4037 - accuracy: 0.6341\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.3999 - accuracy: 0.6341\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3964 - accuracy: 0.6341\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3927 - accuracy: 0.6341\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3889 - accuracy: 0.6341\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3854 - accuracy: 0.6341\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3817 - accuracy: 0.6341\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3782 - accuracy: 0.6341\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3746 - accuracy: 0.6341\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3711 - accuracy: 0.6341\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.3675 - accuracy: 0.6341\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3640 - accuracy: 0.6341\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3604 - accuracy: 0.6341\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3569 - accuracy: 0.6341\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3534 - accuracy: 0.6341\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3500 - accuracy: 0.6341\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3465 - accuracy: 0.6341\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3431 - accuracy: 0.6341\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3397 - accuracy: 0.6341\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3363 - accuracy: 0.6341\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3329 - accuracy: 0.6341\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3297 - accuracy: 0.6341\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3263 - accuracy: 0.6341\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3228 - accuracy: 0.6341\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3193 - accuracy: 0.6341\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.3159 - accuracy: 0.6341\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3127 - accuracy: 0.6341\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3093 - accuracy: 0.6341\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.3058 - accuracy: 0.6341\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.3024 - accuracy: 0.6341\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2990 - accuracy: 0.6341\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2957 - accuracy: 0.6341\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2924 - accuracy: 0.6341\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2890 - accuracy: 0.6341\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2857 - accuracy: 0.6341\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2826 - accuracy: 0.6341\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2793 - accuracy: 0.6341\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2761 - accuracy: 0.6341\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2727 - accuracy: 0.6341\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2697 - accuracy: 0.6341\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2663 - accuracy: 0.6341\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2630 - accuracy: 0.6585\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2599 - accuracy: 0.6829\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2565 - accuracy: 0.6829\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.2535 - accuracy: 0.6829\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2501 - accuracy: 0.6829\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2470 - accuracy: 0.6829\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2438 - accuracy: 0.6829\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2407 - accuracy: 0.6829\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.2377 - accuracy: 0.6829\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2345 - accuracy: 0.6829\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2312 - accuracy: 0.6829\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.2281 - accuracy: 0.6829\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2250 - accuracy: 0.6829\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2220 - accuracy: 0.6829\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2188 - accuracy: 0.7073\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2158 - accuracy: 0.7073\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.2125 - accuracy: 0.7073\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2096 - accuracy: 0.7073\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.2066 - accuracy: 0.7073\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2036 - accuracy: 0.7073\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.2005 - accuracy: 0.7073\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1975 - accuracy: 0.7073\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1943 - accuracy: 0.7073\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.1915 - accuracy: 0.7073\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1886 - accuracy: 0.7073\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1856 - accuracy: 0.7073\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1829 - accuracy: 0.7073\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1799 - accuracy: 0.7073\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1770 - accuracy: 0.7073\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1742 - accuracy: 0.7073\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 524us/step - loss: 1.1713 - accuracy: 0.7073\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1683 - accuracy: 0.7073\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1652 - accuracy: 0.7073\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1625 - accuracy: 0.7073\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1596 - accuracy: 0.7073\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 1.1567 - accuracy: 0.7073\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1540 - accuracy: 0.7073\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1512 - accuracy: 0.7073\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1486 - accuracy: 0.7073\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1458 - accuracy: 0.7073\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1429 - accuracy: 0.7073\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1401 - accuracy: 0.7073\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1372 - accuracy: 0.7073\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1345 - accuracy: 0.7073\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 1.1315 - accuracy: 0.7073\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1290 - accuracy: 0.7073\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1259 - accuracy: 0.7073\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1231 - accuracy: 0.7073\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1203 - accuracy: 0.7073\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1177 - accuracy: 0.7073\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1149 - accuracy: 0.7073\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1123 - accuracy: 0.7073\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.1096 - accuracy: 0.7073\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1069 - accuracy: 0.7073\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.1042 - accuracy: 0.7073\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1014 - accuracy: 0.7073\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0991 - accuracy: 0.7073\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0960 - accuracy: 0.7073\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.7073\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0907 - accuracy: 0.7073\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0879 - accuracy: 0.7073\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0853 - accuracy: 0.7073\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0825 - accuracy: 0.7073\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.0800 - accuracy: 0.7073\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0772 - accuracy: 0.7073\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0745 - accuracy: 0.7073\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0720 - accuracy: 0.7073\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0692 - accuracy: 0.7073\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0666 - accuracy: 0.7073\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.0640 - accuracy: 0.7073\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.7073\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0590 - accuracy: 0.7073\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 1.0563 - accuracy: 0.7073\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0537 - accuracy: 0.7073\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0513 - accuracy: 0.7073\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0486 - accuracy: 0.7073\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0464 - accuracy: 0.7073\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0437 - accuracy: 0.7073\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.7073\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.0385 - accuracy: 0.7073\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0362 - accuracy: 0.7317\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0334 - accuracy: 0.7317\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0312 - accuracy: 0.7317\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.7317\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0262 - accuracy: 0.7317\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0237 - accuracy: 0.7317\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.7317\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0189 - accuracy: 0.7317\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.0167 - accuracy: 0.7317\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0143 - accuracy: 0.7317\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0121 - accuracy: 0.7317\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0098 - accuracy: 0.7317\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0075 - accuracy: 0.7317\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.7317\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0028 - accuracy: 0.7317\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0004 - accuracy: 0.7317\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9981 - accuracy: 0.7317\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9957 - accuracy: 0.7317\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9933 - accuracy: 0.7317\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9910 - accuracy: 0.7317\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.7317\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9862 - accuracy: 0.7317\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9840 - accuracy: 0.7317\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9817 - accuracy: 0.7317\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9793 - accuracy: 0.7317\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9769 - accuracy: 0.7317\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9748 - accuracy: 0.7317\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9722 - accuracy: 0.7317\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9701 - accuracy: 0.7317\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9677 - accuracy: 0.7317\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.7317\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.7317\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.7317\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9586 - accuracy: 0.7317\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9564 - accuracy: 0.7317\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9541 - accuracy: 0.7317\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.9522 - accuracy: 0.7561\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9499 - accuracy: 0.7561\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9477 - accuracy: 0.7561\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9455 - accuracy: 0.7561\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.7561\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9413 - accuracy: 0.7805\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.7805\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9372 - accuracy: 0.7805\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.9351 - accuracy: 0.7805\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.7805\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9310 - accuracy: 0.7805\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.9288 - accuracy: 0.7805\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9268 - accuracy: 0.7805\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9246 - accuracy: 0.7805\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.7805\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9206 - accuracy: 0.7805\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9187 - accuracy: 0.7805\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.9167 - accuracy: 0.7805\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9149 - accuracy: 0.7805\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9128 - accuracy: 0.7805\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9108 - accuracy: 0.7805\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.9085 - accuracy: 0.7805\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.7805\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9045 - accuracy: 0.8049\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.8049\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9004 - accuracy: 0.8049\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8986 - accuracy: 0.8049\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8965 - accuracy: 0.8049\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8945 - accuracy: 0.8049\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8924 - accuracy: 0.8049\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8906 - accuracy: 0.8049\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8888 - accuracy: 0.8049\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8867 - accuracy: 0.8049\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8846 - accuracy: 0.8049\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8825 - accuracy: 0.8049\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8807 - accuracy: 0.8049\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8786 - accuracy: 0.8049\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8765 - accuracy: 0.8049\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8744 - accuracy: 0.8049\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8724 - accuracy: 0.8049\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.8704 - accuracy: 0.8049\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8684 - accuracy: 0.8049\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8663 - accuracy: 0.8049\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8644 - accuracy: 0.8049\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8624 - accuracy: 0.8049\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8606 - accuracy: 0.8049\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8587 - accuracy: 0.8049\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.8568 - accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# データの準備\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sequences = [line.strip() for line in f if line.strip()]\n",
    "    return sequences\n",
    "\n",
    "# シーケンスデータの作成\n",
    "def create_training_data(sequences, char_to_idx):\n",
    "    X, y = [], []\n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq) - 1):\n",
    "            X.append([char_to_idx[char] for char in seq[i:i+2]])  # 2文字ずつ\n",
    "            y.append(char_to_idx[seq[i+2]] if i + 2 < len(seq) else char_to_idx[seq[0]])  # 次の文字 or 循環\n",
    "\n",
    "        # 1文字で次を予測するケース\n",
    "        for i in range(len(seq)):\n",
    "            X.append([char_to_idx[seq[i]], char_to_idx[seq[i]]])  # 同じ文字を2回\n",
    "            y.append(char_to_idx[seq[(i + 1) % len(seq)]])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# モデルの構築\n",
    "def build_model(num_classes):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(10, input_shape=(2, num_classes), activation='tanh'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 学習データの読み込み\n",
    "    file_path = 'data.txt'\n",
    "    sequences = load_data(file_path)\n",
    "\n",
    "    # ユニークな文字を取得\n",
    "    unique_chars = sorted(set(''.join(sequences)))\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "    # データ作成\n",
    "    X, y = create_training_data(sequences, char_to_idx)\n",
    "    X = to_categorical(X, num_classes=len(char_to_idx))\n",
    "    y = to_categorical(y, num_classes=len(char_to_idx))\n",
    "\n",
    "    # モデルの作成と学習\n",
    "    model = build_model(len(char_to_idx))\n",
    "    model.fit(X, y, epochs=500, verbose=1)\n",
    "\n",
    "    # モデル保存\n",
    "    model.save('char_prediction_model.h5')\n",
    "    with open('char_mapping.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(unique_chars))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. モデル実行・追加学習部分 (run_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.utils import to_categorical\n",
    "import tkinter as tk\n",
    "\n",
    "# マッピングの読み込み\n",
    "def load_mappings(mapping_file):\n",
    "    with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "        unique_chars = [line.strip() for line in f]\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "    return unique_chars, char_to_idx, idx_to_char\n",
    "\n",
    "# マッピングの更新\n",
    "def update_mappings(new_chars, mapping_file):\n",
    "    with open(mapping_file, 'a', encoding='utf-8') as f:\n",
    "        for char in new_chars:\n",
    "            f.write(f\"{char}\\n\")\n",
    "\n",
    "# モデルの再構築\n",
    "def rebuild_model(model, num_classes, added_classes):\n",
    "    rnn_weights = model.layers[0].get_weights()\n",
    "    dense_weights = model.layers[1].get_weights()\n",
    "\n",
    "    # RNN層の重みを拡張\n",
    "    rnn_weights[0] = np.pad(rnn_weights[0], ((0, added_classes), (0, 0)), mode='constant')\n",
    "    rnn_weights[1] = np.pad(rnn_weights[1], ((0, 0), (0, added_classes)), mode='constant')\n",
    "    rnn_weights[2] = np.pad(rnn_weights[2], (0, added_classes), mode='constant')\n",
    "\n",
    "    # Dense層の重みを拡張\n",
    "    dense_weights[0] = np.pad(dense_weights[0], ((0, 0), (0, added_classes)), mode='constant')\n",
    "    dense_weights[1] = np.pad(dense_weights[1], (0, added_classes), mode='constant')\n",
    "\n",
    "    # 新しいモデルを構築\n",
    "    new_model = Sequential([\n",
    "        SimpleRNN(10, input_shape=(2, num_classes), activation='tanh'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    new_model.layers[0].set_weights(rnn_weights)\n",
    "    new_model.layers[1].set_weights(dense_weights)\n",
    "    new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return new_model\n",
    "\n",
    "# データセットの作成\n",
    "def create_additional_data(sequences, char_to_idx):\n",
    "    X, y = [], []\n",
    "    for sequence in sequences:\n",
    "        for i in range(len(sequence) - 2):\n",
    "            X.append([char_to_idx[sequence[i]], char_to_idx[sequence[i + 1]]])\n",
    "            y.append(char_to_idx[sequence[i + 2]])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 文字予測\n",
    "def predict_next_char(model, input_seq, char_to_idx, idx_to_char):\n",
    "    if any(char not in char_to_idx for char in input_seq):\n",
    "        return \"未対応の文字が含まれています\"\n",
    "    if len(input_seq) < 2:\n",
    "        input_seq = input_seq * 2\n",
    "    input_encoded = [char_to_idx[char] for char in input_seq[-2:]]\n",
    "    input_encoded = to_categorical(input_encoded, num_classes=len(char_to_idx))\n",
    "    input_encoded = input_encoded[np.newaxis, ...]\n",
    "    prediction = model.predict(input_encoded, verbose=0)\n",
    "    predicted_idx = np.argmax(prediction)\n",
    "    return idx_to_char[predicted_idx]\n",
    "\n",
    "# モデルとマッピングファイルの読み込み\n",
    "model = load_model('char_prediction_model.h5')\n",
    "unique_chars, char_to_idx, idx_to_char = load_mappings('char_mapping.txt')\n",
    "\n",
    "# Tkinter GUI\n",
    "def on_key_release(event=None):\n",
    "    input_seq = input_field.get()\n",
    "    if input_seq:\n",
    "        prediction = predict_next_char(model, input_seq, char_to_idx, idx_to_char)\n",
    "        result_label.config(text=f\"次の文字予測: {prediction}\")\n",
    "    else:\n",
    "        result_label.config(text=\"次の文字予測: \")\n",
    "\n",
    "def on_add_training_data():\n",
    "    global model, char_to_idx, idx_to_char\n",
    "    new_sequence = input_field.get()\n",
    "    if len(new_sequence) < 2:\n",
    "        result_label.config(text=\"2文字以上のシーケンスを入力してください\")\n",
    "        return\n",
    "\n",
    "    # 入力データを `data.txt` に追記\n",
    "    with open('data.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(new_sequence + '\\n')\n",
    "\n",
    "    # 新しい文字を検出\n",
    "    new_chars = [char for char in new_sequence if char not in char_to_idx]\n",
    "    if new_chars:\n",
    "        result_label.config(text=f\"新しい文字を検出: {', '.join(new_chars)}\")\n",
    "        update_mappings(new_chars, 'char_mapping.txt')\n",
    "        unique_chars, char_to_idx, idx_to_char = load_mappings('char_mapping.txt')\n",
    "        model = rebuild_model(model, len(char_to_idx), len(new_chars))\n",
    "\n",
    "    # 追加学習\n",
    "    X_new, y_new = create_additional_data([new_sequence], char_to_idx)\n",
    "    X_new = to_categorical(X_new, num_classes=len(char_to_idx))\n",
    "    y_new = to_categorical(y_new, num_classes=len(char_to_idx))\n",
    "    model.fit(X_new, y_new, epochs=50, verbose=1)\n",
    "\n",
    "    # モデルとマッピングの保存\n",
    "    model.save('char_prediction_model_updated.h5')\n",
    "    with open('char_mapping.txt', 'w', encoding='utf-8') as f:\n",
    "        for char in char_to_idx.keys():\n",
    "            f.write(f\"{char}\\n\")\n",
    "\n",
    "    result_label.config(text=\"データ追記と追加学習が完了しました！\")\n",
    "\n",
    "def show_current_files():\n",
    "    result_label.config(text=\"現在のモデル: char_prediction_model.h5\\nマッピングファイル: char_mapping.txt\")\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"文字予測モデル\")\n",
    "\n",
    "input_field = tk.Entry(root, width=30)\n",
    "input_field.grid(row=0, column=0, padx=10, pady=10)\n",
    "input_field.bind('<KeyRelease>', on_key_release)  # 入力フィールドに文字が入力されるたびに呼び出し\n",
    "\n",
    "train_button = tk.Button(root, text=\"追加学習\", command=on_add_training_data)\n",
    "train_button.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "show_button = tk.Button(root, text=\"現在のファイル\", command=show_current_files)\n",
    "show_button.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.grid(row=2, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "追加学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new shape: (11, 2, 23), Model expects: (None, 2, 17)\n",
      "追加学習を開始します: データ数=11\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_19\" is incompatible with the layer: expected shape=(None, 2, 17), found shape=(None, 2, 23)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# 追加学習\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m追加学習を開始します: データ数=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_new)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# 更新したモデルとマッピングを保存\u001b[39;00m\n\u001b[0;32m     96\u001b[0m updated_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_prediction_model_updated.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filerz3fg2m_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\t-sat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_19\" is incompatible with the layer: expected shape=(None, 2, 17), found shape=(None, 2, 23)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# データの読み込み\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sequences = [line.strip() for line in f if line.strip()]\n",
    "    return sequences\n",
    "\n",
    "# シーケンスデータの作成\n",
    "def create_training_data(sequences, char_to_idx):\n",
    "    X, y = [], []\n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq) - 1):\n",
    "            X.append([char_to_idx[char] for char in seq[i:i+2]])  # 2文字ずつ\n",
    "            y.append(char_to_idx[seq[i+2]] if i + 2 < len(seq) else char_to_idx[seq[0]])  # 次の文字 or 循環\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# マッピングの読み込み\n",
    "def load_mappings(mapping_file):\n",
    "    with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "        unique_chars = [line.strip() for line in f]\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "    return unique_chars, char_to_idx, idx_to_char\n",
    "\n",
    "# マッピングの更新\n",
    "def update_mappings(new_chars, mapping_file):\n",
    "    with open(mapping_file, 'a', encoding='utf-8') as f:\n",
    "        for char in new_chars:\n",
    "            f.write(f\"{char}\\n\")\n",
    "\n",
    "# モデルの再構築\n",
    "def rebuild_model(model, num_classes, added_classes):\n",
    "    rnn_weights = model.layers[0].get_weights()\n",
    "    dense_weights = model.layers[1].get_weights()\n",
    "\n",
    "    # RNN層の重みを拡張\n",
    "    rnn_weights[0] = np.pad(rnn_weights[0], ((0, added_classes), (0, 0)), mode='constant')\n",
    "    rnn_weights[1] = np.pad(rnn_weights[1], ((0, 0), (0, added_classes)), mode='constant')\n",
    "    rnn_weights[2] = np.pad(rnn_weights[2], (0, added_classes), mode='constant')\n",
    "\n",
    "    # Dense層の重みを拡張\n",
    "    dense_weights[0] = np.pad(dense_weights[0], ((0, 0), (0, added_classes)), mode='constant')\n",
    "    dense_weights[1] = np.pad(dense_weights[1], (0, added_classes), mode='constant')\n",
    "\n",
    "    # 新しいモデルを構築\n",
    "    new_model = Sequential([\n",
    "        SimpleRNN(10, input_shape=(2, num_classes), activation='tanh'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    new_model.build(input_shape=(None, 2, num_classes))\n",
    "    new_model.layers[0].set_weights(rnn_weights)\n",
    "    new_model.layers[1].set_weights(dense_weights)\n",
    "    new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return new_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 既存モデルとマッピングの読み込み\n",
    "    model_path = 'char_prediction_model.h5'\n",
    "    mapping_path = 'char_mapping.txt'\n",
    "    additional_data_path = 'data1.txt'\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    unique_chars, char_to_idx, idx_to_char = load_mappings(mapping_path)\n",
    "\n",
    "    # 新しいデータの読み込み\n",
    "    new_sequences = load_data(additional_data_path)\n",
    "\n",
    "    # 新しい文字を検出してマッピングを更新\n",
    "    new_chars = sorted(set(''.join(new_sequences)) - set(unique_chars))\n",
    "    if new_chars:\n",
    "        print(f\"新しい文字を検出: {', '.join(new_chars)}\")\n",
    "        update_mappings(new_chars, mapping_path)\n",
    "        unique_chars, char_to_idx, idx_to_char = load_mappings(mapping_path)\n",
    "        model = rebuild_model(model, len(char_to_idx), len(new_chars))\n",
    "\n",
    "    # 新しいデータで学習\n",
    "    X_new, y_new = create_training_data(new_sequences, char_to_idx)\n",
    "    \n",
    "    # X_new の各シーケンスをワンホットエンコードに変換\n",
    "    X_new = np.array([to_categorical(seq, num_classes=len(char_to_idx)) for seq in X_new])  # (サンプル数, 2, num_classes)\n",
    "    y_new = to_categorical(y_new, num_classes=len(char_to_idx))  # ワンホットエンコード\n",
    "\n",
    "    # モデルの入力形状を確認\n",
    "    print(f\"X_new shape: {X_new.shape}, Model expects: {model.input_shape}\")\n",
    "\n",
    "    # 追加学習\n",
    "    print(f\"追加学習を開始します: データ数={len(X_new)}\")\n",
    "    model.fit(X_new, y_new, epochs=50, verbose=1)\n",
    "\n",
    "    # 更新したモデルとマッピングを保存\n",
    "    updated_model_path = 'char_prediction_model_updated.h5'\n",
    "    model.save(updated_model_path)\n",
    "    print(f\"追加学習が完了しました。モデルを {updated_model_path} に保存しました。\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
